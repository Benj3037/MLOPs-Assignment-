{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#2656a3;\">**Data Engineering and Machine Learning Operations in Business** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Feature selection.\n",
    "2. Feature transformations.\n",
    "3. Training datasets creation.\n",
    "4. Loading the training data.\n",
    "5. Train the model.\n",
    "6. Register model to Hopsworks model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> ‚öôÔ∏è Import of libraries and packages\n",
    "\n",
    "First, we'll install the Python packages required for this notebook. We'll use the --quiet command after specifying the names of the libraries to ensure a silent installation process. Then, we'll proceed to import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing of the packages for the needed libraries for the Jupyter notebook\n",
    "\n",
    "import inspect \n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üì° Connecting to Hopsworks Feature Store\n",
    "\n",
    "We now connect to Hopsworks Feature Store so we can retrieve the feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/556180\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "electricity_fg = fs.get_feature_group(\n",
    "    name='electricity_prices',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_measurements',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "danish_holidays_fg = fs.get_feature_group(\n",
    "    name='danish_holidays',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "forecast_renewable_energy_fg = fs.get_feature_group(\n",
    "    name='forecast_renewable_energy',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üñç Feature View Creation and Retrieving </span>\n",
    "\n",
    "Let's start by selecting all the features you want to include for model training/inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features = electricity_fg.select_all()\\\n",
    "    .join(\n",
    "    weather_fg\\\n",
    "        .select_except([\"timestamp\",\"time\"])\n",
    "        \n",
    "    )\\\n",
    "    .join(\n",
    "        forecast_renewable_energy_fg\\\n",
    "        .select_except([\"timestamp\",\"time\"])\n",
    "    )\\\n",
    "    .join(\n",
    "        danish_holidays_fg.select_all()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#2656a3;\"> ü§ñ Transformation Functions</span>\n",
    "\n",
    "Hopsworks Feature Store provides functionality to attach transformation functions to feature views and comes with built-in transformation functions such as `min_max_scaler`, `standard_scaler`, `robust_scaler` and `label_encoder`.\n",
    "\n",
    "You will preprocess your data using *min-max scaling* on numerical features and *label encoding* on categorical features. To do this you simply define a mapping between our features and transformation functions. This ensures that transformation functions such as *min-max scaling* are fitted only on the training data (and not the validation/test data), which ensures that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_functions = {\n",
    "        \"dk1_spotpricedkk_kwh\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"dk1_offshore_wind_forecastintraday_kwh\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"dk1_onshore_wind_forecastintraday_kwh\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"dk1_solar_forecastintraday_kwh\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"temperature_2m\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"relative_humidity_2m\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"precipitation\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"rain\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"snowfall\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"weather_code\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"cloud_cover\": fs.get_transformation_function(name=\"min_max_scaler\"), \n",
    "        \"wind_speed_10m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "        \"wind_gusts_10m\": fs.get_transformation_function(name=\"min_max_scaler\"),\n",
    "        \"type\": fs.get_transformation_function(name=\"label_encoder\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Feature Views` stands between **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.get_or_create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of a feature group.\n",
    "\n",
    "- `version` - version of a feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingDatasetFeature.__init__() got an unexpected keyword argument 'inference_helper_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melectricity_feature_view\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# will define our 'y' later manualy\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformation_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\feature_store.py:1502\u001b[0m, in \u001b[0;36mFeatureStore.get_or_create_feature_view\u001b[1;34m(self, name, query, version, description, labels, transformation_functions)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature view metadata object or create a new one if it doesn't exist. This method doesn't update\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03mexisting feature view metadata object.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;124;03m    `FeatureView`: The feature view metadata object.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1505\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270181\u001b[39m\n\u001b[0;32m   1506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m\n\u001b[0;32m   1507\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\core\\feature_view_engine.py:96\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[1;32m---> 96\u001b[0m         fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattach_transformation_function(fv)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\core\\feature_view_api.py:100\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[1;34m(self, name, version)\u001b[0m\n\u001b[0;32m     98\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path \u001b[38;5;241m+\u001b[39m [name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_VERSION, version]\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureView\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270009\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\feature_view.py:2411\u001b[0m, in \u001b[0;36mFeatureView.from_response_json\u001b[1;34m(cls, json_dict)\u001b[0m\n\u001b[0;32m   2409\u001b[0m features \u001b[38;5;241m=\u001b[39m json_decamelized\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m   2410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n\u001b[1;32m-> 2411\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_dataset_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingDatasetFeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2417\u001b[0m fv\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m   2418\u001b[0m fv\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [feature\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features \u001b[38;5;28;01mif\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mlabel]\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\feature_view.py:2412\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2409\u001b[0m features \u001b[38;5;241m=\u001b[39m json_decamelized\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[0;32m   2410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n\u001b[0;32m   2411\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 2412\u001b[0m         \u001b[43mtraining_dataset_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingDatasetFeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2415\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[0;32m   2416\u001b[0m     ]\n\u001b[0;32m   2417\u001b[0m fv\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m   2418\u001b[0m fv\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [feature\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features \u001b[38;5;28;01mif\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mlabel]\n",
      "File \u001b[1;32mc:\\Users\\Benj3\\anaconda3\\envs\\bds-streamlit\\Lib\\site-packages\\hsfs\\training_dataset_feature.py:65\u001b[0m, in \u001b[0;36mTrainingDatasetFeature.from_response_json\u001b[1;34m(cls, json_dict)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_response_json\u001b[39m(\u001b[38;5;28mcls\u001b[39m, json_dict):\n\u001b[0;32m     64\u001b[0m     json_decamelized \u001b[38;5;241m=\u001b[39m humps\u001b[38;5;241m.\u001b[39mdecamelize(json_dict)\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjson_decamelized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingDatasetFeature.__init__() got an unexpected keyword argument 'inference_helper_column'"
     ]
    }
   ],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='electricity_feature_view',\n",
    "    version=1,\n",
    "    labels=[], # will define our 'y' later manualy\n",
    "    transformation_functions=transformation_functions,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üèãÔ∏è Training Dataset Creation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#2656a3;\"> ‚õ≥Ô∏è Dataset with train, test and validation splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since you didn't specify 'labels' in feature view creation, it will return None for Y.\n",
    "X_train, X_val, X_test, _, _, _ = feature_view.train_validation_test_split(\n",
    "    train_start=\"2022-01-01\",\n",
    "    train_end=\"2023-06-30\",\n",
    "    validation_start=\"2023-07-01\",\n",
    "    validation_end=\"2023-09-30\",\n",
    "    test_start=\"2023-10-01\",\n",
    "    test_end=\"2023-12-31\",\n",
    "    description='Electricity price prediction dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the training, validation, and test datasets based on the 'time' column\n",
    "X_train.sort_values([\"timestamp\"], inplace=True)\n",
    "X_val.sort_values([\"timestamp\"], inplace=True)\n",
    "X_test.sort_values([\"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'y_train', 'y_val' and 'y_test'\n",
    "y_train = X_train[[\"dk1_spotpricedkk_kwh\"]]\n",
    "y_val = X_val[[\"dk1_spotpricedkk_kwh\"]]\n",
    "y_test = X_test[[\"dk1_spotpricedkk_kwh\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'dare', 'time' and 'timestamp' columns from the training, validation, and test datasets\n",
    "X_train.drop([\"date\", \"time\", \"timestamp\"], axis=1, inplace=True)\n",
    "X_val.drop([\"date\", \"time\", \"timestamp\"], axis=1, inplace=True)\n",
    "X_test.drop([\"date\", \"time\", \"timestamp\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 5 rows of the test dataset (X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üóÉ Window timeseries dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üß¨ Modeling</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'>üóÑ Model Registry</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#2656a3;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference </span>\n",
    "\n",
    "In the next notebook you will use your registered model to predict batch data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
