{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#2656a3;\">**Data Engineering and Machine Learning Operations in Business** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 03: Training Pipeline</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Feature selection.\n",
    "2. Feature transformations.\n",
    "3. Training datasets creation - splitting into train, validation and test sets.\n",
    "4. Loading the training data.\n",
    "5. Training the model.\n",
    "6. Register the model to Hopsworks Model Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> ‚öôÔ∏è Import of libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages for the needed libraries for the Jupyter notebook\n",
    "import inspect \n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üì° Connecting to Hopsworks Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/554133\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "# Importing the hopsworks module\n",
    "import hopsworks\n",
    "\n",
    "# Logging in to the Hopsworks project\n",
    "project = hopsworks.login()\n",
    "\n",
    "# Getting the feature store from the project\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the feature groups\n",
    "electricity_fg = fs.get_feature_group(\n",
    "    name='electricity_prices',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# forecast_renewable_energy_fg = fs.get_feature_group(\n",
    "#     name='forecast_renewable_energy',\n",
    "#     version=1\n",
    "# )\n",
    "\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_measurements',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "danish_calendar_fg = fs.get_feature_group(\n",
    "    name='dk_calendar',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üñç Feature View Creation and Retrieving </span>\n",
    "\n",
    "We first select the features that we want to include for model training.\n",
    "\n",
    "Since we specified `primary_key`as `date` and `timestamp` in part 01 we can now join them together for the `electricity_fg`, `forecast_renewable_energy_fg`, `weather_fg` and `danish_holiday_fg` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training data\n",
    "selected_features_training = electricity_fg.select_all()\\\n",
    "    .join(weather_fg.select_except([\"timestamp\", \"datetime\", \"hour\"]), join_type=\"inner\")\\\n",
    "    .join(danish_calendar_fg.select_all(), join_type=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## .join(forecast_renewable_energy_fg.select_except([\"timestamp\", \"time\"]))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (3.46s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>dk1_spotpricedkk_kwh</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>rain</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_gusts_10m</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1682280000000</td>\n",
       "      <td>2023-04-23 20:00:00+00:00</td>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>20</td>\n",
       "      <td>1.02178</td>\n",
       "      <td>10.4</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1678816800000</td>\n",
       "      <td>2023-03-14 18:00:00+00:00</td>\n",
       "      <td>2023-03-14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.77461</td>\n",
       "      <td>0.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1697259600000</td>\n",
       "      <td>2023-10-14 05:00:00+00:00</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.01551</td>\n",
       "      <td>9.8</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>54.7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1657170000000</td>\n",
       "      <td>2022-07-07 05:00:00+00:00</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>5</td>\n",
       "      <td>1.15795</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647597600000</td>\n",
       "      <td>2022-03-18 10:00:00+00:00</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>10</td>\n",
       "      <td>1.48754</td>\n",
       "      <td>8.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>45.4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                  datetime        date  hour  \\\n",
       "0  1682280000000 2023-04-23 20:00:00+00:00  2023-04-23    20   \n",
       "1  1678816800000 2023-03-14 18:00:00+00:00  2023-03-14    18   \n",
       "2  1697259600000 2023-10-14 05:00:00+00:00  2023-10-14     5   \n",
       "3  1657170000000 2022-07-07 05:00:00+00:00  2022-07-07     5   \n",
       "4  1647597600000 2022-03-18 10:00:00+00:00  2022-03-18    10   \n",
       "\n",
       "   dk1_spotpricedkk_kwh  temperature_2m  relative_humidity_2m  precipitation  \\\n",
       "0               1.02178            10.4                  74.0            0.0   \n",
       "1               0.77461             0.5                  88.0            0.0   \n",
       "2              -0.01551             9.8                  71.0            0.0   \n",
       "3               1.15795            15.0                  90.0            0.1   \n",
       "4               1.48754             8.4                  60.0            0.0   \n",
       "\n",
       "   rain  snowfall  weather_code  cloud_cover  wind_speed_10m  wind_gusts_10m  \\\n",
       "0   0.0       0.0           3.0        100.0             7.6            10.1   \n",
       "1   0.0       0.0           0.0          0.0            11.6            22.7   \n",
       "2   0.0       0.0           1.0         23.0            29.5            54.7   \n",
       "3   0.1       0.0          51.0         59.0            16.6            31.3   \n",
       "4   0.0       0.0           0.0          0.0            21.9            45.4   \n",
       "\n",
       "   dayofweek  day  month  year  holiday  \n",
       "0          6   23      4  2023        1  \n",
       "1          1   14      3  2023        0  \n",
       "2          5   14     10  2023        1  \n",
       "3          3    7      7  2022        0  \n",
       "4          4   18      3  2022        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment this if you would like to view your selected features\n",
    "selected_features_training.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Feature Views` stands between the **Feature Groups** and **Training Dataset**. –°ombining **Feature Groups** we can create **Feature Views** which store a metadata of our data. Having **Feature Views** we can create a **Training Dataset**.\n",
    "\n",
    "The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions.\n",
    "\n",
    "In order to create Feature View we can use `FeatureStore.get_or_create_feature_view()` method.\n",
    "\n",
    "We can specify next parameters:\n",
    "\n",
    "- `name` - name of the feature group.\n",
    "\n",
    "- `version` - version of the feature group.\n",
    "\n",
    "- `labels`- our target variable.\n",
    "\n",
    "- `transformation_functions` - functions to transform our features.\n",
    "\n",
    "- `query` - query object with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/554133/fs/549956/fv/electricity_feature_view/version/1\n"
     ]
    }
   ],
   "source": [
    "# Getting or creating a feature view named 'electricity_feature_view'\n",
    "version = 1 # Defining the version for the feature view\n",
    "feature_view_training = fs.get_or_create_feature_view(\n",
    "    name='electricity_training_feature_view',\n",
    "    version=version,\n",
    "    query=selected_features_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üèãÔ∏è Training Dataset Creation</span>\n",
    "\n",
    "In Hopsworks training data is a query where the projection (set of features) is determined by the parent FeatureView with an optional snapshot on disk of the data returned by the query.\n",
    "\n",
    "**Training Dataset  may contain splits such as:** \n",
    "* Training set - the subset of training data used to train a model.\n",
    "* Validation set - the subset of training data used to evaluate hparams when training a model\n",
    "* Test set - the holdout subset of training data used to evaluate a mode\n",
    "\n",
    "Training dataset is created using `fs.create_training_dataset()` method.\n",
    "\n",
    "**From feature view APIs you can also create training datasts based on even time filters specifing `start_time` and `end_time`** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = feature_view_training.training_data(\n",
    "    description = 'Electricity Prices Training Dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#2656a3;\"> ü§ñ Transformation Functions</span>\n",
    "\n",
    "We preprocess our data using *min-max scaling* on the numerical features and *label encoding* on the one categorical feature we have.\n",
    "To achieve this, we create a mapping between our features and transformation functions. This ensures that transformation functions like min-max scaling are applied exclusively on the training data, preventing any data leakage into the validation or test sets.\n",
    "\n",
    "To achieve this, we create a mapping between our features and transformation functions - ved ikke om man kan sige det her?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Fit the encoder to the data in the 'city_name' column\n",
    "# label_encoder.fit(X[['type']])\n",
    "\n",
    "# # Transform the 'city_name' column data using the fitted encoder\n",
    "# encoded = label_encoder.transform(X[['type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the output of the label encoding to a dense array and concatenate with the original data\n",
    "# X = pd.concat([X, pd.DataFrame(encoded)], axis=1)\n",
    "\n",
    "# Drop columns 'date', 'city_name', 'unix_time' from the DataFrame 'X'\n",
    "X = X.drop(columns=['date', 'datetime', 'timestamp'])\n",
    "\n",
    "# # Rename the newly added column with label-encoded city names to 'city_name_encoded'\n",
    "# X = X.rename(columns={0: \"type_encoded\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable 'pm2_5' from the DataFrame 'X' and assigning it to the variable 'y'\n",
    "y = X.pop('dk1_spotpricedkk_kwh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#2656a3;\"> ‚õ≥Ô∏è Dataset with train, test and validation splits</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets using the train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üß¨ Modeling</span>\n",
    "\n",
    "For Modeling we initialize the XGBoost Regressor.\n",
    "\n",
    "XGBoost Regressor is a powerful and versatile algorithm known for its effectiveness in a wide range of regression tasks, including predictive modeling and time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> ‚öñÔ∏è Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target values on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) using sklearn\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"‚õ≥Ô∏è MSE:\", mse)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) using sklearn\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"‚õ≥Ô∏è RMSE:\", rmse)\n",
    "\n",
    "# Calculate R squared using sklearn\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"‚õ≥Ô∏è R^2:\", r2)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) using sklearn\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"‚õ≥Ô∏è MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">üîß Fine tuning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # TODO: we could parametrize data prep too and test some combinations\n",
    "    # TODO: check params for search grid\n",
    "    'xgb__learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'xgb__max_depth': [3, 4, 5, 6],\n",
    "    'xgb__min_child_weight': [0.5, 1, 3, 5, 7],\n",
    "    'xgb__gamma': [0.0, 0.001, 0.1, 0.2 , 0.3, 0.4],\n",
    "    'xgb__colsample_bytree': [0.5, 0.7, 0.9, 1, 1.5, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_xgb = RandomizedSearchCV(estimator=model, param_distributions=params, verbose=3, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the fine tuned model on the training data\n",
    "gs_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best parameters and the best score obtained from the RandomizedSearchCV\n",
    "display(gs_xgb.best_params_)\n",
    "display(gs_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "gs_model = gs_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test set to get a performance estimate for unseen data\n",
    "# Best model is already re-trained on whole training data! (default for refit=True)\n",
    "y_pred2 = gs_model.predict(X_test)\n",
    "mean_error = mean_absolute_error(y_test, y_pred2)\n",
    "display(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error (MSE) using sklearn\n",
    "mse = mean_squared_error(y_test, y_pred2)\n",
    "print(\"‚õ≥Ô∏è MSE:\", mse)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) using sklearn\n",
    "rmse = mean_squared_error(y_test, y_pred2, squared=False)\n",
    "print(\"‚õ≥Ô∏è RMSE:\", rmse)\n",
    "\n",
    "# Calculate R squared using sklearn\n",
    "r2 = r2_score(y_test, y_pred2)\n",
    "print(\"‚õ≥Ô∏è R^2:\", r2)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) using sklearn\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "print(\"‚õ≥Ô∏è MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions against the expected values\n",
    "plt.bar(x=np.arange(len(y_pred)), height=y_pred, label='predicted', alpha=0.7)\n",
    "plt.bar(x=np.arange(len(y_pred)), height=y_test, label='expected', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the plot_importance function from XGBoost\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot feature importances using the plot_importance function from XGBoost\n",
    "plot_importance(\n",
    "    model, \n",
    "    max_num_features=25,  # Display the top 25 most important features\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'>üóÑ Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the Model Registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">‚öôÔ∏è Model Schema</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of the model's input/output using the features (X_train) and labels (y_train)\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the trained model to a directory\n",
    "model_dir = \"model\"\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the XGBoost regressor as joblib file in the model directory\n",
    "joblib.dump(model, model_dir + \"/dk_electricity_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an entry in the model registry that includes the model's name, desc, metrics\n",
    "xgb_model = mr.python.create_model(\n",
    "    name=\"electricity_price_prediction_model\",\n",
    "    metrics={\n",
    "        \"RMSE\": rmse,\n",
    "        \"MSE\": mse,\n",
    "        \"R squared\": r2,\n",
    "        \"MAE\": mae,\n",
    "    },\n",
    "    model_schema=model_schema,\n",
    "    input_example=X_train.sample(),\n",
    "    description=\"DK1 Electricity Price Predictor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to hopsworks\n",
    "xgb_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\">‚è≠Ô∏è **Next:** Part 04: Batch Inference </span>\n",
    "\n",
    "Next notebook we will use the registered model to make predictions based on the batch data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
