{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#2656a3;\">**Data Engineering and Machine Learning Operations in Business** </span> <span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 04: Batch Inference</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Load batch data.\n",
    "2. Predict using model from Model Registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> ‚öôÔ∏è Import of libraries and packages\n",
    "\n",
    "First, we'll install the Python packages required for this notebook. We'll use the --quiet command after specifying the names of the libraries to ensure a silent installation process. Then, we'll proceed to import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages for the needed libraries for the Jupyter notebook\n",
    "import joblib\n",
    "import inspect \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import os\n",
    "\n",
    "#%config InlineBackend.figure_format='retina'\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2656a3;\"> üì° Connecting to Hopsworks Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the hopsworks module\n",
    "import hopsworks\n",
    "\n",
    "# Logging in to the Hopsworks project\n",
    "project = hopsworks.login()\n",
    "\n",
    "# Getting the feature store from the project\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#2656a3'> ‚öôÔ∏è Feature View Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the 'electricity_feature_view' feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='electricity_feature_view',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:#2656a3'> üóÑ Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> üìÆ Retrieving model from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the model from the Model Registry\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"electricity_price_prediction_model\", \n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Downloading the saved model to a local directory\n",
    "saved_model_dir = retrieved_model.download()\n",
    "\n",
    "# Loading the saved XGB model\n",
    "retrieved_xgboost_model = joblib.load(saved_model_dir + \"/dk_electricity_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the retrieved XGBoost regressor model\n",
    "retrieved_xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:#2656a3'> ‚ú® Load Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Calculating the start date as 5 days ago from the current date\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=5)\n",
    "\n",
    "# Converting the start date to a timestamp in milliseconds\n",
    "start_time = int(start_date.timestamp()) * 1000\n",
    "\n",
    "# Displaying the start date in timestamp format\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing batch scoring\n",
    "feature_view.init_batch_scoring(1)\n",
    "\n",
    "# Retrieving batch data from the feature view starting from the specified start time\n",
    "batch_data = feature_view.get_batch_data(\n",
    "    start_time=start_time,\n",
    ")\n",
    "\n",
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we go one back in our directory to access the folder with our functions\n",
    "%cd ..\n",
    "\n",
    "# Now we import the functions from the features folder\n",
    "# This is the functions we have created to generate features for electricity prices and weather measures\n",
    "from features import electricity_prices, weather_measures \n",
    "\n",
    "# We go back into the notebooks folder\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching weather forecast measures for the next 5 days\n",
    "weather_forecast_df = weather_measures.forecast_weather_measures(\n",
    "    forecast_length=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file with calender\n",
    "calender_df = pd.read_csv('https://raw.githubusercontent.com/Camillahannesbo/MLOPs-Assignment-/main/data/calendar_incl_holiday.csv', delimiter=';', usecols=['date', 'type'])\n",
    "\n",
    "calender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Formatting the date column to 'YYYY-MM-DD' dateformat\n",
    "calender_df[\"date\"] = calender_df[\"date\"].map(lambda x: datetime.strptime(x, '%d/%m/%Y').strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features to the calender dataframe\n",
    "calender_df['date_'] = pd.to_datetime(calender_df['date'])\n",
    "calender_df['day'] = calender_df['date_'].dt.dayofweek\n",
    "calender_df['month'] = calender_df['date_'].dt.month\n",
    "calender_df['holiday'] = np.where(calender_df['type'] == 'Not a Workday', 1, 0)\n",
    "\n",
    "# Drop the columns 'type' and 'date_' to finalize the calender dataframe\n",
    "calender_df = calender_df.drop(['type','date_'], axis=1)\n",
    "\n",
    "merged_df = pd.merge(weather_forecast_df, calender_df, how='inner', left_on='date', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the batch data\n",
    "batch_data = merged_df\n",
    "\n",
    "batch_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü§ñ Making the predictions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Fit the encoder to the data in the 'city_name' column\n",
    "# label_encoder.fit(batch_data[['type']])\n",
    "\n",
    "# # Transform the 'city_name' column data using the fitted encoder\n",
    "# encoded = label_encoder.transform(batch_data[['type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the output of the label encoding to a dense array and concatenate with the original data\n",
    "# X_batch = pd.concat([batch_data, pd.DataFrame(encoded)], axis=1)\n",
    "\n",
    "X_batch = batch_data\n",
    "\n",
    "# Drop columns 'date', 'city_name', 'unix_time' from the DataFrame 'X'\n",
    "X_batch = X_batch.drop(columns=['date', 'time', 'timestamp'])\n",
    "\n",
    "# # Rename the newly added column with label-encoded city names to 'city_name_encoded'\n",
    "# X_batch = X_batch.rename(columns={0: \"type_encoded\"})\n",
    "\n",
    "# Displaying the first 5 rows of the modified DataFrame\n",
    "X_batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable 'dk1_spotpricedkk_kwh' from the batch data\n",
    "y_batch = X_batch.pop('dk1_spotpricedkk_kwh')\n",
    "\n",
    "# Displaying the first 5 rows of the modified DataFrame\n",
    "y_batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the batch data using the retrieved XGBoost regressor model\n",
    "predictions = retrieved_xgboost_model.predict(X_batch)\n",
    "\n",
    "# Display the first 5 predictions\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = batch_data[\"time\"]\n",
    "y_pred = retrieved_xgboost_model.predict(X_batch)\n",
    "\n",
    "data = {\n",
    "    'prediction': [y_pred],\n",
    "    'time': [label],\n",
    "}\n",
    "\n",
    "monitor_df = pd.DataFrame(data)\n",
    "monitor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = batch_data[\"time\"]\n",
    "y_pred = retrieved_xgboost_model.predict(X_batch)\n",
    "\n",
    "data = {\n",
    "    'prediction': y_pred,\n",
    "    'time': label,\n",
    "}\n",
    "\n",
    "monitor_df = pd.DataFrame(data)\n",
    "monitor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27;\">üëæ Next is creating our Streamlit App?</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bds-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
